{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Models",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yORoCjBODigm"
      },
      "outputs": [],
      "source": [
        "# All imports here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All constants, paths here\n",
        "processed_train_data_path = '/content/drive/MyDrive/Quora_Question_Pair_Similarity/data/processed_train_data.csv'\n",
        "alphas = [10 ** x for x in range(-5, 2)] # hyperparameter for SGD classifier.\n",
        "train_result_message = 'The log loss for the given train data is :: '\n",
        "test_result_message = 'The log loss for the given test data is :: '"
      ],
      "metadata": {
        "id": "bauxkGDGEItY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the processed train data\n",
        "df = pd.read_csv(processed_train_data_path)"
      ],
      "metadata": {
        "id": "izsIcMOxEGnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A22Sy5VEbXE",
        "outputId": "82c02efa-a7fc-4b0b-9ac6-81762366e309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404287, 221)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjtwOjthGDRy",
        "outputId": "364a5ae7-e6fc-4956-8052-a9c1badb72ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'id', 'qid1', 'qid2', 'question1', 'question2',\n",
              "       'is_duplicate', 'q1_length', 'q2_length', 'n_words_q1',\n",
              "       ...\n",
              "       '86_y', '87_y', '88_y', '89_y', '90_y', '91_y', '92_y', '93_y', '94_y',\n",
              "       '95_y'],\n",
              "      dtype='object', length=221)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data and label from the csv file\n",
        "data = df.drop(columns=['id','is_duplicate', 'Unnamed: 0', 'qid1', 'qid2', 'question1', 'question2'])\n",
        "class_labels = df['is_duplicate']"
      ],
      "metadata": {
        "id": "e5yb6ADsF1K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test(validation)\n",
        "X_train,X_test, y_train, y_test = train_test_split(data, class_labels, stratify=class_labels, test_size=0.3)"
      ],
      "metadata": {
        "id": "mLMdWKRWFo-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyper_parameter_tuning(X_train, X_test, y_train, y_test, loss_type, regularization = 'l2',  method_name='sigmoid'):\n",
        "  \"\"\"\n",
        "  Helper method to perform hyper parameter tuning for a model of given type\n",
        "  \"\"\"\n",
        "  log_errors = []\n",
        "  for alpha in alphas:\n",
        "    sgd = SGDClassifier(alpha=alpha, penalty=regularization, loss=loss_type, random_state=42)\n",
        "    sgd.fit(X_train, y_train)\n",
        "    classifier = CalibratedClassifierCV(sgd, method=method_name)\n",
        "    classifier.fit(X_train,y_train)\n",
        "    y_predicted = classifier.predict_proba(X_test)\n",
        "    log_errors.append(log_loss(y_test, y_predicted, labels=sgd.classes_, eps=1e-15))\n",
        "    print('For values of alpha = ', alpha, \"The log loss is:\", log_errors[-1])\n",
        "  return log_errors"
      ],
      "metadata": {
        "id": "iIu17yztG7-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(X_train, X_test, y_train, y_test, loss_type, regularization = 'l2',  method_name='sigmoid'):\n",
        "  \"\"\"\n",
        "  Helper method that builds best model after hyper paramter tuning\n",
        "  \"\"\"\n",
        "  log_errors = hyper_parameter_tuning(X_train, X_test, y_train, y_test, loss_type=loss_type)\n",
        "  best_alpha_index = np.argmin(log_errors)\n",
        "  sgd = SGDClassifier(alpha=alphas[best_alpha_index], penalty=regularization, loss=loss_type, random_state=42)\n",
        "  sgd.fit(X_train, y_train)\n",
        "  classifier = CalibratedClassifierCV(sgd, method=method_name)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  return classifier"
      ],
      "metadata": {
        "id": "frK6KeaXLnTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluator(X,y,model, print_message):\n",
        "  \"\"\"\n",
        "  Evaluate the loss on the trained model for given data and true labels\n",
        "  \"\"\"\n",
        "  y_predicted = model.predict_proba(X)\n",
        "  print(print_message,log_loss(y, y_predicted, labels=model.classes_, eps=1e-15))\n",
        "  y_predicted =np.argmax(y_predicted,axis=1)\n",
        "  print(\"The accuracy is :: \", accuracy_score(y,y_predicted))"
      ],
      "metadata": {
        "id": "jHNdFFHAM6U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IZ4nkXperJg",
        "outputId": "45c45b84-a2c7-4b6a-8f9d-4c1a3e1f85c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(283000, 214)\n",
            "(283000,)\n",
            "(121287, 214)\n",
            "(121287,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression: Build the best model using hyper-parameter tuning \n",
        "logistic_regression = build_model(X_train, X_test, y_train, y_test, 'log')\n",
        "# Evaluate on Train data\n",
        "model_evaluator(X_train,y_train,logistic_regression, train_result_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAhpZ8VGJRgj",
        "outputId": "070b8804-562b-42b2-8b43-bdb05103a22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For values of alpha =  1e-05 The log loss is: 0.49842252315293656\n",
            "For values of alpha =  0.0001 The log loss is: 0.49057970277743757\n",
            "For values of alpha =  0.001 The log loss is: 0.5168597183688719\n",
            "For values of alpha =  0.01 The log loss is: 0.5075494029634705\n",
            "For values of alpha =  0.1 The log loss is: 0.5200618184796122\n",
            "For values of alpha =  1 The log loss is: 0.5344019524891788\n",
            "For values of alpha =  10 The log loss is: 0.5522338613871465\n",
            "The log loss for the given train data is ::  0.493348976317517\n",
            "The accuracy is ::  0.738095406360424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Validation data\n",
        "model_evaluator(X_test,y_test,logistic_regression, test_result_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9YLAnuaewZA",
        "outputId": "8a4d1875-3681-42f8-e9c5-3c156d8662ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The log loss for the given test data is ::  0.49057970277743757\n",
            "The accuracy is ::  0.740392622457477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM: Build the best model using hyper-parameter tuning \n",
        "svm_linear = build_model(X_train, X_test, y_train, y_test, 'hinge', 'l1')\n",
        "# Evaluate on Train data\n",
        "model_evaluator(X_train,y_train,svm_linear, train_result_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vjDv8M6MWuM",
        "outputId": "e480f402-6277-4f09-d9c5-523f648b846f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For values of alpha =  1e-05 The log loss is: 0.49213601331291373\n",
            "For values of alpha =  0.0001 The log loss is: 0.4953479140085616\n",
            "For values of alpha =  0.001 The log loss is: 0.5061265299815904\n",
            "For values of alpha =  0.01 The log loss is: 0.5053030392198005\n",
            "For values of alpha =  0.1 The log loss is: 0.5174989250815675\n",
            "For values of alpha =  1 The log loss is: 0.5322175307759471\n",
            "For values of alpha =  10 The log loss is: 0.546939805781072\n",
            "The log loss for the given train data is ::  0.5198646148303241\n",
            "The accuracy is ::  0.7191095406360424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Validation data\n",
        "model_evaluator(X_test,y_test,svm_linear, test_result_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu26SxNzM1VT",
        "outputId": "e148e067-7e78-4342-d65e-75b513a26471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The log loss for the given test data is ::  0.5180447806342268\n",
            "The accuracy is ::  0.7192856612827426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_tuning_xgb():\n",
        "  \"\"\"\n",
        "  Helper method to do hyperparameter tuning for XgBoost Classifier\n",
        "  \"\"\"\n",
        "  # Grid params for Tuning\n",
        "  params = {\n",
        "    \"learning_rate\"    : [0.05, 0.10, 0.15],\n",
        "    \"max_depth\"        : [6, 8, 10, 12, 15],\n",
        "    \"gamma\"            : [ 0.1, 0.2 , 0.3, 0.4 ],\n",
        "    \"eta\"              : [0.01, 0.02, 0.09, 0.1, 0.2]\n",
        "  }\n",
        "\n",
        "  # Do grid search and print the best params\n",
        "  classifier=xgb.XGBClassifier()\n",
        "  grid_search= GridSearchCV(classifier, param_grid=params, scoring='f1', n_jobs=-1, cv=3, verbose=3) \n",
        "  grid_search.fit(X_train, y_train)\n",
        "  print(\"Best Params: \", grid_search.best_params_)\n",
        "  return None"
      ],
      "metadata": {
        "id": "nJaX6Cy5mS2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params={\n",
        " \"learning_rate\"    : [0.05, 0.10, 0.15] ,\n",
        " \"max_depth\"        : [6, 8, 10, 12, 15],\n",
        " \"gamma\"            : [ 0.1, 0.2 , 0.3, 0.4 ],\n",
        " \"eta\"              : [0.01, 0.02, 0.09, 0.1, 0.2]\n",
        "}"
      ],
      "metadata": {
        "id": "LB3FkBdtT8ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=xgb.XGBClassifier()"
      ],
      "metadata": {
        "id": "AxkvZbhDVzcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search= GridSearchCV(classifier, param_grid=params, scoring='f1', n_jobs=-1, cv=3, verbose=3) "
      ],
      "metadata": {
        "id": "4cNCjwm8VPn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IytxhyStWAK4",
        "outputId": "72e16ca7-9435-4c02-afcf-24236aa9260e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "NkdWOJOPX8Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {}\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eval_metric'] = 'logloss'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 4\n",
        "\n",
        "d_train = xgb.DMatrix(X_train, label=y_train)\n",
        "d_test = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "watchlist = [(d_train, 'train'), (d_test, 'valid')]\n",
        "\n",
        "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
        "\n",
        "xgdmat = xgb.DMatrix(X_train,y_train)\n",
        "predict_y = bst.predict(d_test)\n",
        "print(\"The test log loss is:\",log_loss(y_test, predict_y, eps=1e-15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ZVvlNvOh0E",
        "outputId": "cbfded0c-7f57-4e27-a196-3e6d8e663ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-logloss:0.685289\tvalid-logloss:0.685939\n",
            "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
            "\n",
            "Will train until valid-logloss hasn't improved in 20 rounds.\n",
            "[10]\ttrain-logloss:0.626307\tvalid-logloss:0.626625\n",
            "[20]\ttrain-logloss:0.583398\tvalid-logloss:0.583949\n",
            "[30]\ttrain-logloss:0.551853\tvalid-logloss:0.552592\n",
            "[40]\ttrain-logloss:0.528634\tvalid-logloss:0.529123\n",
            "[50]\ttrain-logloss:0.510506\tvalid-logloss:0.511018\n",
            "[60]\ttrain-logloss:0.496122\tvalid-logloss:0.496771\n",
            "[70]\ttrain-logloss:0.484781\tvalid-logloss:0.485489\n",
            "[80]\ttrain-logloss:0.475765\tvalid-logloss:0.476519\n",
            "[90]\ttrain-logloss:0.468471\tvalid-logloss:0.469274\n",
            "[100]\ttrain-logloss:0.462296\tvalid-logloss:0.463114\n",
            "[110]\ttrain-logloss:0.45701\tvalid-logloss:0.458212\n",
            "[120]\ttrain-logloss:0.453026\tvalid-logloss:0.454141\n",
            "[130]\ttrain-logloss:0.449452\tvalid-logloss:0.450591\n",
            "[140]\ttrain-logloss:0.446384\tvalid-logloss:0.447756\n",
            "[150]\ttrain-logloss:0.443653\tvalid-logloss:0.445281\n",
            "[160]\ttrain-logloss:0.441401\tvalid-logloss:0.443081\n",
            "[170]\ttrain-logloss:0.439368\tvalid-logloss:0.441136\n",
            "[180]\ttrain-logloss:0.437837\tvalid-logloss:0.439475\n",
            "[190]\ttrain-logloss:0.436234\tvalid-logloss:0.438119\n",
            "[200]\ttrain-logloss:0.434683\tvalid-logloss:0.43678\n",
            "[210]\ttrain-logloss:0.4334\tvalid-logloss:0.435508\n",
            "[220]\ttrain-logloss:0.432234\tvalid-logloss:0.434315\n",
            "[230]\ttrain-logloss:0.43106\tvalid-logloss:0.433368\n",
            "[240]\ttrain-logloss:0.429957\tvalid-logloss:0.432338\n",
            "[250]\ttrain-logloss:0.429015\tvalid-logloss:0.431468\n",
            "[260]\ttrain-logloss:0.427943\tvalid-logloss:0.430463\n",
            "[270]\ttrain-logloss:0.426989\tvalid-logloss:0.429573\n",
            "[280]\ttrain-logloss:0.425997\tvalid-logloss:0.428662\n",
            "[290]\ttrain-logloss:0.42492\tvalid-logloss:0.427763\n",
            "[300]\ttrain-logloss:0.4239\tvalid-logloss:0.426912\n",
            "[310]\ttrain-logloss:0.423049\tvalid-logloss:0.426178\n",
            "[320]\ttrain-logloss:0.422134\tvalid-logloss:0.425372\n",
            "[330]\ttrain-logloss:0.421317\tvalid-logloss:0.424665\n",
            "[340]\ttrain-logloss:0.420467\tvalid-logloss:0.423922\n",
            "[350]\ttrain-logloss:0.419652\tvalid-logloss:0.42322\n",
            "[360]\ttrain-logloss:0.418873\tvalid-logloss:0.422549\n",
            "[370]\ttrain-logloss:0.418063\tvalid-logloss:0.421848\n",
            "[380]\ttrain-logloss:0.417237\tvalid-logloss:0.421152\n",
            "[390]\ttrain-logloss:0.416503\tvalid-logloss:0.420533\n",
            "[399]\ttrain-logloss:0.415836\tvalid-logloss:0.419968\n",
            "The test log loss is: 0.41995842114595455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pZdB9oOWfaes"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}